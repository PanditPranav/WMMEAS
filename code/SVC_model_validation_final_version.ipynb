{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\falco\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'jaccard_similarity_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a6a1dd2b4325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#from WRMDpy import WRMDalert as alert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mWRMDpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_data\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mWRMDpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSyndrome\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mSyndrome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\directory\\WMMEAS\\WRMDpy\\Syndrome.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#nltk.download()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_ml\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#!/usr/bin/env python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelSeries\u001b[0m       \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minfo\u001b[0m                         \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m__version__\u001b[0m     \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_ml\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#!/usr/bin/env python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelFrame\u001b[0m       \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelSeries\u001b[0m     \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_ml\\core\\frame.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimbaccessors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimbaccessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskaccessors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mskaccessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmaccessors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msmaccessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnsaccessors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msnsaccessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_ml\\skaccessors\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearModelMethods\u001b[0m                 \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mManifoldMethods\u001b[0m                        \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetricsMethods\u001b[0m                          \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelSelectionMethods\u001b[0m           \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNeighborsMethods\u001b[0m                      \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_ml\\skaccessors\\metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    254\u001b[0m _true_pred_methods = (_classification_methods + _regression_methods\n\u001b[0;32m    255\u001b[0m                       + _cluster_methods)\n\u001b[1;32m--> 256\u001b[1;33m \u001b[0m_attach_methods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMetricsMethods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_wrap_target_pred_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_true_pred_methods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_ml\\core\\accessor.py\u001b[0m in \u001b[0;36m_attach_methods\u001b[1;34m(cls, wrap_func, methods)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0m_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} already has '{1}' method\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'jaccard_similarity_score'"
     ]
    }
   ],
   "source": [
    "import os as os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('C:/Users/falco/Desktop/directory/WMMEAS/')\n",
    "data_path = 'C:/Users/falco/Desktop/directory/WMMEAS data/'\n",
    "#from WRMDpy import WRMDalert as alert\n",
    "from WRMDpy import read_data as rd\n",
    "from WRMDpy import Syndrome as Syndrome\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_palette(\"husl\", 5)\n",
    "plt.rcParams['figure.figsize'] = (12, 12)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['axes.labelsize'] = plt.rcParams['font.size']\n",
    "plt.rcParams['axes.titlesize'] = 1.5*plt.rcParams['font.size']\n",
    "plt.rcParams['legend.fontsize'] = plt.rcParams['font.size']\n",
    "plt.rcParams['xtick.labelsize'] = plt.rcParams['font.size']\n",
    "plt.rcParams['ytick.labelsize'] = plt.rcParams['font.size']\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['xtick.minor.size'] = 3\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 3\n",
    "plt.rcParams['ytick.minor.size'] = 3\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['legend.loc'] = 'center left'\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "#plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import\n",
    "from sklearn.model_selection import StratifiedKFold ,cross_val_score, train_test_split, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import learning_curve\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from textblob import TextBlob\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = Syndrome.read_data(data_path+'\\Training dataset_WMME_May 7 2018.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.condition_predict.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.condition_predict.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Condition.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "h_data = Syndrome.read_data_historic(data_path+'\\historic_data_2013-01-01_2018-05-22_above_all major centers.csv')\n",
    "h_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h_data.Admitted_at.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_data.Admitted_at.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_tokens(message):\n",
    "    message = unicode(message, 'utf8')  # convert bytes into proper unicode\n",
    "    return TextBlob(message).words\n",
    "\n",
    "\n",
    "def split_into_lemmas(message):\n",
    "    message = unicode(message, 'utf8').lower()\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]\n",
    "\n",
    "\n",
    "def bag_of_words(data_frame, historical_data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_frame['Condition'], data_frame['condition_predict'], test_size=0.2, random_state=0)\n",
    "    \n",
    "    count_vect = CountVectorizer(analyzer=split_into_lemmas,ngram_range= (1, 3), encoding='utf8',stop_words =None)\n",
    "    X_train_counts = count_vect.fit_transform(X_train)\n",
    "    \n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    \n",
    "    print('Training shape')\n",
    "    print (X_train_tfidf.shape)\n",
    "    \n",
    "    X_new_counts = count_vect.transform(X_test)\n",
    "    X_test_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "    print ('Testing shape')\n",
    "    print (X_test_tfidf.shape)\n",
    "    \n",
    "    \n",
    "    print ('Historical data')\n",
    "    X_hist_counts = count_vect.transform(historical_data['ConditionO'])\n",
    "    X_hist_tfidf = tfidf_transformer.transform(X_hist_counts)\n",
    "    print (X_hist_tfidf.shape)\n",
    "\n",
    "    \n",
    "    return X_train_tfidf, y_train, X_test_tfidf, y_test, X_hist_tfidf, count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_tfidf, y_train, X_test_tfidf, y_test, X_hist_tfidf, count_vectrotize_obj = bag_of_words(data_frame= data, historical_data= h_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features = count_vectrotize_obj.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Set the parameters by cross-validation\n",
    "#tuned_parameters = [{'n_estimators': [10, 100],\n",
    "#           'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#           'max_depth' : [3, 6],\n",
    "#           'criterion' :['gini', 'entropy']}]\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                     'gamma': [1e-3, 1e-4, 1e-3, 1e-5],\n",
    "                     'C': [1, 10, 100, 100, 1000], \n",
    "                    'probability':[True]},\n",
    "                   \n",
    "                    {'kernel': ['linear'], 'C': [0.25,1, 10, 100, 1000], 'probability':[True]}, \n",
    "                    {'kernel': ['poly'], 'C': [0.25, 1, 10, 100, 1000], 'probability':[True], \n",
    "                     'degree':[1,3,5], 'gamma':[1,2, 4,8]}\n",
    "                   ]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score, verbose = 1,  n_jobs= -1)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "       \n",
    "    y_true, y_pred = y_test, clf.predict(X_test_tfidf)\n",
    "    print(\"Accuracy of SVC on holdout data: \",accuracy_score(y_true,y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "print('Running the model with best parameters')\n",
    "\n",
    "scores = cross_val_score(clf.best_estimator_, X_train_tfidf, y_train, cv = 5)\n",
    "\n",
    "print('Accuracy of model on cross validation dataset while training')\n",
    "print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))\n",
    "y_pred = cross_val_predict(clf.best_estimator_, X_train_tfidf, y_train, cv = 5)\n",
    "df = pd.DataFrame({'prediction':y_pred, 'obsevred': y_train})\n",
    "confusion_matrix = ConfusionMatrix(df.obsevred, df.prediction)\n",
    "#print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n",
    "#confusion_matrix.print_stats()\n",
    "print('Confusion matrix showing classification on cross validation dataset while training')\n",
    "confusion_matrix.plot(normalized=False, backend='seaborn', cmap='Blues',annot= True)\n",
    "plt.show()\n",
    "\n",
    "print('Best paraamters for the algorithm\\n')\n",
    "print (clf.best_estimator_)\n",
    "best_svc = clf.best_estimator_\n",
    "y_true, y_pred = y_test, clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy of SVC on holdout data: \",accuracy_score(y_true,y_pred))\n",
    "\n",
    "df = pd.DataFrame({'prediction':y_pred, 'obsevred': y_test})\n",
    "confusion_matrix = ConfusionMatrix(df.obsevred, df.prediction)\n",
    "#print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n",
    "#confusion_matrix.print_stats()\n",
    "confusion_matrix.plot(normalized=False, backend='seaborn', cmap='Blues',annot= True, fmt='.0f')\n",
    "plt.savefig(data_path+'/Best_model.png', dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "probs = pd.DataFrame(clf.predict_proba(X_test_tfidf), columns=clf.classes_)\n",
    "arr = np.argsort(-probs.values, axis=1)\n",
    "df1 = pd.DataFrame(probs.columns[arr], index=probs.index)\n",
    "df1.columns = ['rank_'+ str(col)  for col in df1.columns]\n",
    "final_svc = pd.concat([df.reset_index(0), probs], axis=1)\n",
    "final_svc = pd.concat([df.reset_index(0), probs, df1], axis=1)\n",
    "def correct_classification(c):\n",
    "    if c.obsevred ==  c.prediction:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "final_svc['correct_prediction'] = final_svc.apply(correct_classification, axis=1)\n",
    "\n",
    "def matching_two_methods(c):\n",
    "    if c.prediction ==  c['rank_0']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "final_svc['method_match'] = final_svc.apply(matching_two_methods, axis=1)\n",
    "\n",
    "\n",
    "def matching_rank_2(c):\n",
    "    if c.method_match ==  0:\n",
    "        if c.obsevred ==  c['rank_1']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0 \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "final_svc['match_rank_2'] = final_svc.apply(matching_rank_2, axis=1)\n",
    "\n",
    "def adjust_prediction(c):\n",
    "    if c.method_match ==  0:\n",
    "        return c['rank_1']\n",
    "    else:\n",
    "        return c['prediction']\n",
    "\n",
    "final_svc['prediction_adjusted'] = final_svc.apply(adjust_prediction, axis=1)\n",
    "\n",
    "\n",
    "final_svc.to_csv('C:/Users/Falco/Desktop/directory/WRMD_paper/outputs/final_figures/final_svc.csv')\n",
    "\n",
    "print ('Adjusting the predictions\\nby comparing class wise prediction probabilities and predicted classes\\n')\n",
    "\n",
    "print(\"Accuracy of SVC on holdout data: \",accuracy_score(final_svc['obsevred'],final_svc['prediction_adjusted']))\n",
    "print()\n",
    "df = final_svc[['obsevred','prediction_adjusted']]\n",
    "confusion_matrix = ConfusionMatrix(df.obsevred, df.prediction_adjusted)\n",
    "#print(\"Confusion matrix:\\n%s\" % confusion_matrix)\n",
    "#confusion_matrix.print_stats()\n",
    "confusion_matrix.plot(normalized=False, backend='seaborn', cmap='Blues',annot= True, fmt='.0f')\n",
    "plt.savefig('C:/Users/Falco/Desktop/directory/WRMD_paper/outputs/final_figures/Final_model.png', dpi = 600)\n",
    "cm = confusion_matrix.to_dataframe()\n",
    "cm.to_csv('C:/Users/Falco/Desktop/directory/WRMD_paper/outputs/final_figures/confusion_matrix.csv')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax1 = plt.subplots(ncols=1, nrows=1, figsize =(6,6))\n",
    "cm.replace(0, np.nan, inplace= True)\n",
    "sns.heatmap(cm, cmap='GnBu', mask=cm.isnull(),annot=True, fmt='.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax1 = plt.subplots(ncols=1, nrows=1, figsize =(6,6))\n",
    "cm.replace(0, np.nan, inplace= True)\n",
    "sns.heatmap(cm, cmap='GnBu', annot=True, fmt='.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.to_dataframe().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix.to_dataframe().fillna(0).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_perc = confusion_matrix.to_dataframe().fillna(0)\n",
    "cm_perc = (cm_perc.fillna(0).T/cm_perc.fillna(0).sum(axis = 1)).T\n",
    "cm_perc.replace(0, np.nan, inplace= True)\n",
    "fig, ax1 = plt.subplots(ncols=1, nrows=1, figsize =(8,8))\n",
    "sns.heatmap(cm_perc, cmap='GnBu', annot=True, fmt='.2f', annot_kws={\"size\": 11})\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/Falco/Desktop/directory/WRMD_paper/outputs/final_figures/Figure2_confusion_matrix.png', dpi = 600)\n",
    "plt.savefig('C:/Users/Falco/Desktop/directory/WRMD_paper/outputs/final_figures/Figure2_confusion_matrix.svg', dpi = 600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_perc = confusion_matrix.to_dataframe().fillna(0)\n",
    "cm_perc = (cm_perc.fillna(0).T/cm_perc.fillna(0).sum(axis = 1)).T\n",
    "cm_perc.replace(0, np.nan, inplace= True)\n",
    "fig, ax1 = plt.subplots(ncols=1, nrows=1, figsize =(8*0.66,8*0.66))\n",
    "sns.heatmap(cm_perc, cmap='GnBu', annot=True, fmt='.2f', annot_kws={\"size\": 11*0.66})\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/Falco/Desktop/directory/WRMD_paper/outputs/final_figures/Figure2_confusion_matrix_v2.png', dpi = 600)\n",
    "plt.savefig('C:/Users/Falco/Desktop/directory/WRMD_paper/outputs/final_figures/Figure2_confusion_matrix_v2.svg', dpi = 600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_perc.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "lw = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#1b9e77', '#d95f02', '#7570b3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 4\n",
    "def plot_ROC(start, end , ax, fpr, tpr, roc_auc):\n",
    "    colors = ['#1b9e77', '#d95f02', '#7570b3','#e7298a']\n",
    "    for i, color, s in zip(range(start, end), colors, clf.classes_[start:end]):\n",
    "        name = 'ROC ' + clf.classes_[i]+'(area = {1:0.2f})'\n",
    "        ax.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='{0} (AUC = {1:0.2f})'\n",
    "                 ''.format(s, roc_auc[i]))\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    ax.set_xlim([-0.05, 1.0])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(y_train))\n",
    "probs = clf.predict_proba(X_test_tfidf)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, probs[:, i], pos_label = clf.classes_[i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), probs.ravel())\n",
    "#roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "cmap = sns.color_palette(\"Set2\", 12)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "# Plot all ROC curves\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, nrows=1, figsize =(18,6))\n",
    "plot_ROC(start = 0, end = 4 , ax = ax1, fpr = fpr, tpr =tpr , roc_auc = roc_auc)\n",
    "plot_ROC(start = 4, end = 8 , ax = ax2, fpr = fpr, tpr =tpr , roc_auc = roc_auc)\n",
    "plot_ROC(start = 8, end = 12 , ax = ax3, fpr = fpr, tpr =tpr , roc_auc = roc_auc)\n",
    "plt.savefig('C:\\Users\\Falco\\Desktop\\directory\\WRMD_paper\\outputs\\ROC_curves.png', dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)\n",
    "\n",
    "\n",
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "\n",
    "def top_mean_feats(X_train_tfidf, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = X_train_tfidf[grp_ids].toarray()\n",
    "    else:\n",
    "        D = X_train_tfidf.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_feats_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    \n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = []\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df['label'] = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframes = top_feats_by_class(Xtr= X_test_tfidf, y= y_test, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    df.set_index('feature').plot(kind = 'barh', title = df.label.unique()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on historical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predhist = clf.predict(X_hist_tfidf)\n",
    "probs_hist = pd.DataFrame(clf.predict_proba(X_hist_tfidf), columns=clf.classes_, index= h_data.index)\n",
    "arr = np.argsort(-probs_hist.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(probs_hist.columns[arr], index=h_data.index)\n",
    "df2.columns = ['rank_'+ str(col)  for col in df2.columns]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "hist_final = h_data\n",
    "hist_final['prediction'] =predhist \n",
    "hist_final = pd.concat([hist_final, probs_hist, df2], axis=1)\n",
    "hist_final['method_match'] = hist_final.apply(matching_two_methods, axis=1)\n",
    "\n",
    "def adjust_prediction(c):\n",
    "    if c.method_match ==  0:\n",
    "        return c['rank_0']\n",
    "    else:\n",
    "        return c['prediction']\n",
    "\n",
    "final_svc['prediction_adjusted'] = final_svc.apply(adjust_prediction, axis=1)\n",
    "\n",
    "hist_final['prediction_adjusted'] = hist_final.apply(adjust_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "hist_final.to_csv(data_path+'/Predicted_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final fit with all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_tokens(message):\n",
    "    message = unicode(message, 'utf8')  # convert bytes into proper unicode\n",
    "    return TextBlob(message).words\n",
    "\n",
    "\n",
    "def split_into_lemmas(message):\n",
    "    message = unicode(message, 'utf8').lower()\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]\n",
    "\n",
    "\n",
    "def bag_of_words_complete_model(data_frame):\n",
    "    print('count vectorize')\n",
    "    count_vect = CountVectorizer(analyzer=split_into_lemmas,ngram_range= (1, 3), encoding='utf8',stop_words =None)\n",
    "    X_counts = count_vect.fit_transform(data_frame['Condition'])\n",
    "    \n",
    "    print('tfid tranformer')\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "    \n",
    "    print('Training model on complete training dataset')\n",
    "    print (X_tfidf.shape)\n",
    "    \n",
    "    return X_tfidf, data_frame['condition_predict'], count_vect, tfidf_transformer\n",
    "\n",
    "best_svc = SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "                  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "                  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message = unicode(message, 'utf8').lower()\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=split_into_lemmas,ngram_range= (1, 3), encoding='utf8',stop_words =None)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "text_clf = Pipeline([('vect', count_vect), ('tdif', tfidf_transformer), ('clf', best_svc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "text_clf.fit(X=data['Condition'], y=data['condition_predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(text_clf, 'classification_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_tfidf, Y, count_vectrotize_obj_complete , tfidf_transformer_object= bag_of_words_complete_model(data_frame= data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_svc = SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "                  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "                  tol=0.001, verbose=False)\n",
    "best_svc.fit(X=X_tfidf, y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping the model into a .pkl file for later use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(best_svc, 'Syndrom_classification_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(count_vectrotize_obj_complete, 'count_vectrotize_obj_complete.pkl')\n",
    "joblib.dump(tfidf_transformer_object, 'tfidf_transformer_object.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
